{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import erica\n",
    "from erica.core import *\n",
    "from erica.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sqlalchemy import distinct, and_, desc\n",
    "from sqlalchemy.sql import func\n",
    "import janome.tokenizer\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constant:\n",
    "    irex_tags = [\"location\", \"organization\", \"person\", \"date\", \"artifact\", \"time\", \"money\", \"percent\"]\n",
    "    tags_path = Config.get(\"corpus.root\") + \"/\" + Config.get(\"corpus.tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vector:\n",
    "    def __init__(self, tuples = None, dictionary = None):\n",
    "        if dictionary is not None:\n",
    "            self.data = dictionary\n",
    "            return\n",
    "\n",
    "        self.data = {}\n",
    "        \n",
    "        if tuples is None:\n",
    "            return\n",
    "\n",
    "        for k, v in tuples:\n",
    "            self.data[k] = v\n",
    "\n",
    "    def __add__(self, other):\n",
    "        data = {}\n",
    "        for k in set(self.data.keys()) | set(other.data.keys()):\n",
    "            data[k] = self.data.get(k, 0) + other.data.get(k, 0)\n",
    "\n",
    "        return Vector(None, dictionary = data)\n",
    "\n",
    "    def __truediv__(self, scalar):\n",
    "        data = {}\n",
    "        for k, v in self.data.items():\n",
    "            data[k] = v / scalar\n",
    "\n",
    "        return Vector(None, dictionary = data)\n",
    "\n",
    "    def norm(self):\n",
    "        return math.sqrt(sum([v * v for k, v in self.data.items()]))\n",
    "    \n",
    "    def normalized(self):\n",
    "        norm = self.norm()\n",
    "        return Vector([(k, v / norm) for k, v in self.data.items()])\n",
    "\n",
    "    @classmethod\n",
    "    def distance(cls, v1, v2):\n",
    "        return math.sqrt(sum([(v1.data.get(k, 0) - v2.data.get(k, 0)) ** 2 for k in set(v1.data.keys()) | set(v2.data.keys())]))\n",
    "\n",
    "    @classmethod\n",
    "    def center(cls, vs):\n",
    "        total = Vector()\n",
    "        for v in vs:\n",
    "            total += v\n",
    "\n",
    "        return total / len(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_tokenizer = janome.tokenizer.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(records):\n",
    "    irex_tags = Constant.irex_tags\n",
    "    store = { tag: [] for tag in irex_tags }\n",
    "\n",
    "    for record in records:\n",
    "        tags = [target for target in irex_tags if target in record[\"tags\"]]\n",
    "\n",
    "        if len(tags) == 1:\n",
    "            tag = tags[0]\n",
    "            store[tag].append(record[\"word\"])\n",
    "\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_entries(n):\n",
    "    max_id = Session.query(func.max(Entry.id).label(\"max_id\")).one().max_id\n",
    "    sample_id_list = random.sample(range(1, max_id + 1), n)\n",
    "\n",
    "    return Session.query(Entry, PlainText)\\\n",
    "        .join(PlainText, Entry.id == PlainText.entry_id)\\\n",
    "        .filter(Entry.id.in_(sample_id_list))\\\n",
    "        .all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_bow(dictionary, title, text):\n",
    "    words = [word for line in text.split(\"\\n\") for word in global_tokenizer.tokenize(line, wakati = True)]\n",
    "    dictionary.add_documents([words])\n",
    "    return dictionary.doc2bow(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_clusters(dictionary, annotated_clusters, *, debug = False):\n",
    "    document_map = {}\n",
    "    clusters = {}\n",
    "\n",
    "    for tag, entities in annotated_clusters.items():\n",
    "        entries = Session.query(Entry, PlainText)\\\n",
    "            .join(PlainText, Entry.id == PlainText.entry_id)\\\n",
    "            .filter(Entry.title.in_(entities))\\\n",
    "            .all()\n",
    "        for entry, plain_text in entries:\n",
    "            if debug:\n",
    "                print(entry.title, len(plain_text.text))\n",
    "            document_map[entry.title] = Vector(document_to_bow(dictionary, entry.title, plain_text.text)).normalized()\n",
    "\n",
    "        if len(entries) > 0:\n",
    "            clusters[tag] = {}\n",
    "            clusters[tag][\"entities\"] = [entry.title for entry, _ in entries]\n",
    "            clusters[tag][\"center\"] = Vector.center([document_map[entry.title] for entry, _ in entries])\n",
    "\n",
    "    return clusters, document_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_clusters(dictionary, document_map, clusters, records, *, debug = False):\n",
    "    for entry, plain_text in records:\n",
    "        entity = entry.title\n",
    "        word_vector = Vector(document_to_bow(dictionary, entity, plain_text.text)).normalized()\n",
    "        document_map[entry.title] = word_vector\n",
    "        min_tag = None\n",
    "        min_dist = 100000000\n",
    "        for tag in clusters:\n",
    "            dist = Vector.distance(clusters[tag][\"center\"], word_vector)\n",
    "            if min_dist > dist:\n",
    "                min_dist = dist\n",
    "                min_tag = tag\n",
    "        clusters[min_tag][\"entities\"].append(entity)\n",
    "        clusters[min_tag][\"center\"] = Vector.center([document_map[entity] for entity in clusters[min_tag][\"entities\"]])\n",
    "        if debug:\n",
    "            print(entity, min_tag, max(clusters[min_tag][\"center\"].data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_clusters = separate(File.load_yaml(Constant.tags_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters, document_map = initialize_clusters(dictionary, pre_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = sample_entries(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "expand_clusters(dictionary, document_map, clusters, records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
